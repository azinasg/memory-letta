{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e5f77a-6406-4d19-ac08-0cd968faf831",
   "metadata": {},
   "source": [
    "# Programming Agent Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63196bdb-3d82-497e-8ef6-630372823d0c",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44ffa5-ea48-4bb9-8933-10cd30ac9d30",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc6632-f3d5-4ea3-8ee3-db85193912ae",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126f43f-eba6-4dce-9df5-c884fd4ffd19",
   "metadata": {},
   "source": [
    "Letta agents persist information over time and restarts by saving data to a database. These lessons do not require past information. To enable a clean restart, the database is cleared before starting the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3698ae50-4b95-4ab2-9438-0567cd64d2b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!rm  -f ~/.letta/sqlite.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77cfcd-3155-4e60-bb01-3a4e1292863c",
   "metadata": {},
   "source": [
    "## Section 0: Setup a MemGPT client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137aa217-24bb-4372-b21c-37f21a945c9d",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azinasgarian/miniconda3/envs/mem/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_endpoint\" in Step has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letta.letta.server.server - INFO - Creating sqlite engine sqlite:////Users/azinasgarian/.letta/sqlite.db\n"
     ]
    }
   ],
   "source": [
    "from letta import create_client \n",
    "\n",
    "client = create_client() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from letta.schemas.llm_config import LLMConfig\n",
    "from letta.schemas.embedding_config import EmbeddingConfig\n",
    "\n",
    "\n",
    "# Set the default llm config\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\"))\n",
    "\n",
    "# Set the default embedding config\n",
    "client.set_default_embedding_config(EmbeddingConfig.default_config(\"text-embedding-ada-002\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c66c27-e5f4-407b-aeb1-d5ad4f063111",
   "metadata": {},
   "source": [
    "## Section 1: Memory Blocks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b601a6-875c-4476-a6aa-68ad830b7bf6",
   "metadata": {},
   "source": [
    "### Understanding ChatMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "chat_memory = ChatMemory(\n",
    "    human=\"Name: Bob\", \n",
    "    persona=\"You are a helpful assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['persona', 'human']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.list_block_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(value='Name: Bob', limit=5000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-38d6ed0c-da95-43eb-9854-1b06cfc28d87', organization_id=None, created_by_id=None, last_updated_by_id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.get_block(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e0b63a-b8e7-4958-8c81-71dce3328391",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2cc3dd-0278-40f7-8c0e-e919cb628c31",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def core_memory_append(agent_state: \"AgentState\", label: str, content: str) -> Optional[str]:  # type: ignore\n",
      "        \"\"\"\n",
      "        Append to the contents of core memory.\n",
      "\n",
      "        Args:\n",
      "            label (str): Section of the memory to be edited (persona or human).\n",
      "            content (str): Content to write to the memory. All unicode (including emojis) are supported.\n",
      "\n",
      "        Returns:\n",
      "            Optional[str]: None is always returned as this function does not produce a response.\n",
      "        \"\"\"\n",
      "        current_value = str(agent_state.memory.get_block(label).value)\n",
      "        new_value = current_value + \"\\n\" + str(content)\n",
      "        agent_state.memory.update_block_value(label=label, value=new_value)\n",
      "        return None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(chat_memory.core_memory_append))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33374545-64f8-4f79-92b4-f6a80851336a",
   "metadata": {},
   "source": [
    "#### Context compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf728dce-f06b-4bcb-a3ba-15a7f099b2d9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{% for block in blocks %}<{{ block.label }} characters=\"{{ block.value|length }}/{{ block.limit }}\">\\n{{ block.value }}\\n</{{ block.label }}>{% if not loop.last %}\\n{% endif %}{% endfor %}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de7b9f35-8599-4465-952a-b2db2d7b1533",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<persona characters=\"27/5000\">\\nYou are a helpful assistant\\n</persona>\\n<human characters=\"9/5000\">\\nName: Bob\\n</human>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3b0de-e3ed-413c-852a-71efae8a591d",
   "metadata": {},
   "source": [
    "## Section 2: Defining a custom memory module\n",
    "\n",
    "In this section, we're going to define a custom memory module called `TaskMemory`. This module will be used to store and manage tasks for a user in the core memory along with the human and persona. We'll also implement 2 functions to manage the task queue called `task_queue_push` and `task_queue_pop`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f41239-463e-4609-8870-cbbae06a8f3a",
   "metadata": {},
   "source": [
    "### Defining a memory module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d419bd-020c-4f6f-81c3-e704d65f5306",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory\n",
    "from letta.schemas.block import Block\n",
    "from typing import Optional, List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7",
   "metadata": {
    "height": 829
   },
   "outputs": [],
   "source": [
    "class TaskMemory(ChatMemory): \n",
    "\n",
    "    def __init__(self, human: str, persona: str, tasks: str): \n",
    "        super().__init__(human=human, persona=persona, limit=2000) \n",
    "        self.set_block(Block(limit=2000, value=json.dumps(tasks), label=\"tasks\"))\n",
    "\n",
    "    def task_queue_push(self: \"Agent\", task_description: str):\n",
    "        \"\"\"\n",
    "        Push to a task queue stored in core memory. \n",
    "\n",
    "        Args:\n",
    "            task_description (str): A description of the next task you must accomplish. \n",
    "            \n",
    "        Returns:\n",
    "            Optional[str]: None is always returned as this function \n",
    "            does not produce a response.\n",
    "        \"\"\"\n",
    "        import json\n",
    "        tasks = json.loads(self.memory.get_block(\"tasks\").value)\n",
    "        tasks.append(task_description)\n",
    "        self.memory.update_block_value(\"tasks\", json.dumps(tasks))\n",
    "        return None\n",
    "\n",
    "    def task_queue_pop(self: \"Agent\"):\n",
    "        \"\"\"\n",
    "        Get the next task from the task queue \n",
    " \n",
    "        Returns:\n",
    "            Optional[str]: The description of the task popped from the \n",
    "            queue, if there are still tasks in queue. Otherwise, returns\n",
    "            None (the task queue is empty)\n",
    "        \"\"\"\n",
    "        import json\n",
    "        tasks = json.loads(self.memory.get_block(\"tasks\").value)\n",
    "        if len(tasks) == 0: \n",
    "            return None\n",
    "        task = tasks[0]\n",
    "        print(\"CURRENT TASKS: \", tasks)\n",
    "        self.memory.update_block_value(\"tasks\", json.dumps(tasks[1:]))\n",
    "        return task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534a35b-506b-44fc-b658-d213a7eed2f9",
   "metadata": {},
   "source": [
    "### Creating an agent with custom `TaskMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "571e53e5-4190-4787-9cb2-efc527885c2d",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "task_agent_name = \"task_agent\"\n",
    "\n",
    "task_agent_state = client.create_agent(\n",
    "    name=task_agent_name, \n",
    "    system = open(\"task_queue_system_prompt.txt\", \"r\").read(),\n",
    "    memory=TaskMemory(\n",
    "        human=\"My name is Azin\", \n",
    "        persona=\"You are an agent that must clear its tasks.\", \n",
    "        tasks=[]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2534c3f7-55d9-4f5f-892c-82221ccd1b78",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "message = \"Task 1: Explain my name, Task 2: Tell me a story about my name in less than 100 words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85ddb91c-5d8c-4f1c-87fd-f8c2b75f7990",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 22, 15, 11, 412864, tzinfo=datetime.timezone.utc) updated_at=None id='message-9557aa75-117b-430a-ab4b-4092f5d378c2' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"Adding user's name to core memory for personalization.\")] organization_id=None agent_id='agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_jfl7Ez0jYeRPhyVs8yugPEo3', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"content\": \"Azin\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_append'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Request to call function core_memory_append with tool_call_id: call_jfl7Ez0jYeRPhyVs8yugPEo3\n",
      "Letta.letta.services.agent_manager - INFO - Rebuilding system with new memory...\n",
      "Diff:\n",
      "--- \n",
      "+++ \n",
      "@@ -60,7 +60,7 @@\n",
      " Base instructions finished.\n",
      " From now on, you are going to act as your persona and remember to call `task_queue_pop` every time.\n",
      " \n",
      "-### Memory [last modified: 2025-02-10 05:15:09 PM EST-0500]\n",
      "+### Memory [last modified: 2025-02-10 05:15:11 PM EST-0500]\n",
      " 0 previous messages between you and the user are stored in recall memory (use functions to access them)\n",
      " 0 total memories you created are stored in archival memory (use functions to access them)\n",
      " \n",
      "@@ -71,6 +71,7 @@\n",
      " <tasks characters=\"2/2000\">\n",
      " []\n",
      " </tasks>\n",
      "-<human characters=\"15/2000\">\n",
      "+<human characters=\"20/2000\">\n",
      " My name is Azin\n",
      "+Azin\n",
      " </human>\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 22, 15, 13, 804367, tzinfo=datetime.timezone.utc) updated_at=None id='message-b97c7b67-1893-43fd-a5ca-9d1c72dbdd28' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='Tasks received from the user. Preparing to fulfill them.')] organization_id=None agent_id='agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_JAn85xA0WqxUmqjkZhT3Mtva', function=Function(arguments='{\\n  \"message\": \"Your name, Azin, has Persian roots, meaning \\\\\"intelligent\\\\\" or \\\\\"wise.\\\\\" It represents a person with great insight and understanding. Now, let me tell you a short story: Once, there was a wise sage named Azin who traveled the world, sharing knowledge and solving problems. People sought him out, knowing his intelligence could guide them through life\\'s challenges.\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Request to call function send_message with tool_call_id: call_JAn85xA0WqxUmqjkZhT3Mtva\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">Adding user&#x27;s name to core memory for personalization.</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">core_memory_append</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"label\"</span>: <span class=\"json-key\">\"human\",<br>&nbsp;&nbsp;\"content\"</span>: <span class=\"json-key\">\"Azin\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 05:15:11 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">Tasks received from the user. Preparing to fulfill them.</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Your name, Azin, has Persian roots, meaning \\\"</span>intelligent\\\" or \\\"wise.\\\" It represents a person with great insight and understanding. Now, let me tell you a short story: Once, there was a wise sage named Azin who traveled the world, sharing knowledge and solving problems. People sought him out, knowing his intelligence could guide them through life's challenges.\"<br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 05:15:13 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">146</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">4642</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">4788</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">2</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-9557aa75-117b-430a-ab4b-4092f5d378c2', date=datetime.datetime(2025, 2, 10, 22, 15, 11, 412864, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"Adding user's name to core memory for personalization.\"), ToolCallMessage(id='message-9557aa75-117b-430a-ab4b-4092f5d378c2', date=datetime.datetime(2025, 2, 10, 22, 15, 11, 412864, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='core_memory_append', arguments='{\\n  \"label\": \"human\",\\n  \"content\": \"Azin\",\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_jfl7Ez0jYeRPhyVs8yugPEo3')), ToolReturnMessage(id='message-3a3eb35b-bedd-4833-b3d0-bd9891762821', date=datetime.datetime(2025, 2, 10, 22, 15, 11, 506441, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 05:15:11 PM EST-0500\"\\n}', status='success', tool_call_id='call_jfl7Ez0jYeRPhyVs8yugPEo3', stdout=None, stderr=None), ReasoningMessage(id='message-b97c7b67-1893-43fd-a5ca-9d1c72dbdd28', date=datetime.datetime(2025, 2, 10, 22, 15, 13, 804367, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning='Tasks received from the user. Preparing to fulfill them.'), ToolCallMessage(id='message-b97c7b67-1893-43fd-a5ca-9d1c72dbdd28', date=datetime.datetime(2025, 2, 10, 22, 15, 13, 804367, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"Your name, Azin, has Persian roots, meaning \\\\\"intelligent\\\\\" or \\\\\"wise.\\\\\" It represents a person with great insight and understanding. Now, let me tell you a short story: Once, there was a wise sage named Azin who traveled the world, sharing knowledge and solving problems. People sought him out, knowing his intelligence could guide them through life\\'s challenges.\"\\n}', tool_call_id='call_JAn85xA0WqxUmqjkZhT3Mtva')), ToolReturnMessage(id='message-032f4b7d-81d9-4c2f-b5a4-dbd9a35547a3', date=datetime.datetime(2025, 2, 10, 22, 15, 13, 808743, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 05:15:13 PM EST-0500\"\\n}', status='success', tool_call_id='call_JAn85xA0WqxUmqjkZhT3Mtva', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=146, prompt_tokens=4642, total_tokens=4788, step_count=2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=message\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd0a88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Persona(value='You are an agent that must clear its tasks.', limit=2000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-13a176c4-04a9-4ee7-8eb0-4c498f86d625', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None),\n",
       " Block(value='[]', limit=2000, template_name=None, is_template=False, label='tasks', description=None, metadata={}, id='block-267f452b-e779-43e1-b760-561577b57066', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None),\n",
       " Human(value='My name is Azin', limit=2000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-3ba4155f-b488-4175-ac6e-5e460a27f30e', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_agent_state.memory.get_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 22, 15, 15, 771812, tzinfo=datetime.timezone.utc) updated_at=None id='message-d9a69155-386f-42c6-942d-db549f0d80ad' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User wants me to confirm task completion. I should clarify that tasks are already done.')] organization_id=None agent_id='agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_nXVo2R0wWldyh9xkBj9Iviw2', function=Function(arguments='{\\n  \"message\": \"I\\'ve completed the tasks you set! If you have more questions or need assistance, feel free to let me know.\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Request to call function send_message with tool_call_id: call_nXVo2R0wWldyh9xkBj9Iviw2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User wants me to confirm task completion. I should clarify that tasks are already done.</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"I've completed the tasks you set! If you have more questions or need assistance, feel free to let me know.\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 05:15:15 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">59</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">2595</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">2654</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">1</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-d9a69155-386f-42c6-942d-db549f0d80ad', date=datetime.datetime(2025, 2, 10, 22, 15, 15, 771812, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning='User wants me to confirm task completion. I should clarify that tasks are already done.'), ToolCallMessage(id='message-d9a69155-386f-42c6-942d-db549f0d80ad', date=datetime.datetime(2025, 2, 10, 22, 15, 15, 771812, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"I\\'ve completed the tasks you set! If you have more questions or need assistance, feel free to let me know.\"\\n}', tool_call_id='call_nXVo2R0wWldyh9xkBj9Iviw2')), ToolReturnMessage(id='message-619a2465-0364-40ca-88fd-47db9bff9534', date=datetime.datetime(2025, 2, 10, 22, 15, 15, 776753, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 05:15:15 PM EST-0500\"\\n}', status='success', tool_call_id='call_nXVo2R0wWldyh9xkBj9Iviw2', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=59, prompt_tokens=2595, total_tokens=2654, step_count=1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"complete your tasks\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356e2cb1-a89a-4e56-8bed-1aabfd92bb09",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Persona(value='You are an agent that must clear its tasks.', limit=2000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-13a176c4-04a9-4ee7-8eb0-4c498f86d625', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None),\n",
       " Block(value='[]', limit=2000, template_name=None, is_template=False, label='tasks', description=None, metadata={}, id='block-267f452b-e779-43e1-b760-561577b57066', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None),\n",
       " Human(value='My name is Azin\\nAzin', limit=2000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-3ba4155f-b488-4175-ac6e-5e460a27f30e', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_core_memory(task_agent_state.id).get_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70253b9-7737-4427-906a-69e69c964c8d",
   "metadata": {},
   "source": [
    "> copy the id='block-...' string, from the code cell above \"client.get_core_memory...\", and then paste into the code cell client.get_block('block-...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6e64ee5-fc01-436c-839a-73e65fb162c9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(client.get_block('cut_and_paste_id_from_above'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "228ba181-b0bf-4f04-bf94-1e520caeafc3",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 22, 15, 17, 838406, tzinfo=datetime.timezone.utc) updated_at=None id='message-c41b8943-93a7-4bd2-9d91-ebaefac5d756' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"User seems to be repeating the request. I'll reiterate that there are no outstanding tasks.\")] organization_id=None agent_id='agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_sGSvLDUGETb1mQeDaW2MkDL3', function=Function(arguments='{\\n  \"message\": \"All tasks are complete, Azin! If you have anything else in mind or new tasks for me, just let me know!\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Request to call function send_message with tool_call_id: call_sGSvLDUGETb1mQeDaW2MkDL3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User seems to be repeating the request. I&#x27;ll reiterate that there are no outstanding tasks.</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"All tasks are complete, Azin! If you have anything else in mind or new tasks for me, just let me know!\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 05:15:17 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">63</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">2746</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">2809</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">1</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-c41b8943-93a7-4bd2-9d91-ebaefac5d756', date=datetime.datetime(2025, 2, 10, 22, 15, 17, 838406, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"User seems to be repeating the request. I'll reiterate that there are no outstanding tasks.\"), ToolCallMessage(id='message-c41b8943-93a7-4bd2-9d91-ebaefac5d756', date=datetime.datetime(2025, 2, 10, 22, 15, 17, 838406, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"All tasks are complete, Azin! If you have anything else in mind or new tasks for me, just let me know!\"\\n}', tool_call_id='call_sGSvLDUGETb1mQeDaW2MkDL3')), ToolReturnMessage(id='message-b2319799-3001-449d-9ed0-df09e6111ae1', date=datetime.datetime(2025, 2, 10, 22, 15, 17, 844816, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 05:15:17 PM EST-0500\"\\n}', status='success', tool_call_id='call_sGSvLDUGETb1mQeDaW2MkDL3', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=63, prompt_tokens=2746, total_tokens=2809, step_count=1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"complete your tasks\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Persona(value='You are an agent that must clear its tasks.', limit=2000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-13a176c4-04a9-4ee7-8eb0-4c498f86d625', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None),\n",
       " Block(value='[]', limit=2000, template_name=None, is_template=False, label='tasks', description=None, metadata={}, id='block-267f452b-e779-43e1-b760-561577b57066', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None),\n",
       " Human(value='My name is Azin\\nAzin', limit=2000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-3ba4155f-b488-4175-ac6e-5e460a27f30e', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_core_memory(task_agent_state.id).get_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d452213f-b977-4a88-ba56-726216a9d218",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 22, 15, 19, 725239, tzinfo=datetime.timezone.utc) updated_at=None id='message-c35d55db-205d-4643-a580-5640c35d646c' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"User is curious about memory. I'll explain without revealing too much technical detail.\")] organization_id=None agent_id='agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_2LnLbbHqQDBgH66KNFklHtGV', function=Function(arguments='{\\n  \"message\": \"The memory I have about you is stored internally, allowing me to remember your name, Azin, and provide a more personalized experience. If there\\'s something specific you\\'d like me to recall or discuss, just let me know!\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fcbce9ce-ff80-4b09-a1c0-9fcbc0ee3afb - INFO - Request to call function send_message with tool_call_id: call_2LnLbbHqQDBgH66KNFklHtGV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User is curious about memory. I&#x27;ll explain without revealing too much technical detail.</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"The memory I have about you is stored internally, allowing me to remember your name, Azin, and provide a more personalized experience. If there's something specific you'd like me to recall or discuss, just let me know!\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 05:15:19 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">78</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">2902</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">2980</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">1</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-c35d55db-205d-4643-a580-5640c35d646c', date=datetime.datetime(2025, 2, 10, 22, 15, 19, 725239, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"User is curious about memory. I'll explain without revealing too much technical detail.\"), ToolCallMessage(id='message-c35d55db-205d-4643-a580-5640c35d646c', date=datetime.datetime(2025, 2, 10, 22, 15, 19, 725239, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"The memory I have about you is stored internally, allowing me to remember your name, Azin, and provide a more personalized experience. If there\\'s something specific you\\'d like me to recall or discuss, just let me know!\"\\n}', tool_call_id='call_2LnLbbHqQDBgH66KNFklHtGV')), ToolReturnMessage(id='message-7f998528-d5a4-464b-abc6-f5f7d62436f3', date=datetime.datetime(2025, 2, 10, 22, 15, 19, 731370, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 05:15:19 PM EST-0500\"\\n}', status='success', tool_call_id='call_2LnLbbHqQDBgH66KNFklHtGV', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=78, prompt_tokens=2902, total_tokens=2980, step_count=1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"Where is that memory?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2629195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Persona(value='You are an agent that must clear its tasks.', limit=2000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-13a176c4-04a9-4ee7-8eb0-4c498f86d625', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_agent_state.memory.get_block(\"persona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43343ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
