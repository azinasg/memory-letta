{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d94fb77-0e21-4a69-b0a5-22d4043896ce",
   "metadata": {},
   "source": [
    "# Lab 3: Building Agents with memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a96f8-1bc3-4997-8768-987c95639696",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a53c6-cac9-410c-868b-bf4e4fcd59e7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0d506-81de-4257-8f1e-1ccc3af54962",
   "metadata": {},
   "source": [
    "Letta agents persist information over time and restarts by saving data to a database. These lessons do not require past information. To enable a clean restart, the database is cleared before starting the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb06a83c-2621-4382-9707-df4fcfbe421d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!rm  -f ~/.letta/sqlite.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbebca-7bf9-4eba-b3cb-3d5abf8bcecc",
   "metadata": {},
   "source": [
    "## Section 0: Setup a client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137aa217-24bb-4372-b21c-37f21a945c9d",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azinasgarian/miniconda3/envs/mem/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_endpoint\" in Step has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letta.letta.server.server - INFO - Creating sqlite engine sqlite:////Users/azinasgarian/.letta/sqlite.db\n"
     ]
    }
   ],
   "source": [
    "from letta import create_client \n",
    "\n",
    "client = create_client() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from letta.schemas.llm_config import LLMConfig\n",
    "from letta.schemas.embedding_config import EmbeddingConfig\n",
    "\n",
    "\n",
    "# Set the default llm config\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\"))\n",
    "\n",
    "# Set the default embedding config\n",
    "client.set_default_embedding_config(EmbeddingConfig.default_config(\"text-embedding-ada-002\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29744677-0b25-4a22-85f9-b7ca1635477c",
   "metadata": {},
   "source": [
    "## Section 1: Creating a simple agent with memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37703a17-7bfb-48b8-b321-a2debcf0341f",
   "metadata": {},
   "source": [
    "### Creating an agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "agent_name = \"simple_agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52b2313-1c8f-4119-aeaa-451198f161a9",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# this is not in the video. It deletes the agent if you are running this a 2nd time.\n",
    "if client.get_agent_id(agent_name): \n",
    "    client.delete_agent(client.get_agent_id(agent_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory\n",
    "\n",
    "agent_state = client.create_agent(\n",
    "    name=agent_name, \n",
    "    memory=ChatMemory(\n",
    "        human=\"My name is Sarah\", \n",
    "        persona=\"You are a helpful assistant that loves emojis\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 13, 751960, tzinfo=datetime.timezone.utc) updated_at=None id='message-4a71479a-5f29-47b0-aec2-ea815a80c8f3' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User has logged in and greeted me. Time to respond warmly!')] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_skJAhna2I7lqzY7kueSbDGcJ', function=Function(arguments='{\\n  \"message\": \"Hey there! ðŸŒŸ How\\'s it going?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function send_message with tool_call_id: call_skJAhna2I7lqzY7kueSbDGcJ\n"
     ]
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message=\"hello!\", \n",
    "    role=\"user\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7b9f35-8599-4465-952a-b2db2d7b1533",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User has logged in and greeted me. Time to respond warmly!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Hey there! ðŸŒŸ How's it going?\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:13 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">43</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">2018</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">2061</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">1</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-4a71479a-5f29-47b0-aec2-ea815a80c8f3', date=datetime.datetime(2025, 2, 10, 19, 15, 13, 751960, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning='User has logged in and greeted me. Time to respond warmly!'), ToolCallMessage(id='message-4a71479a-5f29-47b0-aec2-ea815a80c8f3', date=datetime.datetime(2025, 2, 10, 19, 15, 13, 751960, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"Hey there! ðŸŒŸ How\\'s it going?\"\\n}', tool_call_id='call_skJAhna2I7lqzY7kueSbDGcJ')), ToolReturnMessage(id='message-5e22b6bd-3569-49ae-a482-e02f2ed99ab0', date=datetime.datetime(2025, 2, 10, 19, 15, 13, 756972, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:13 PM EST-0500\"\\n}', status='success', tool_call_id='call_skJAhna2I7lqzY7kueSbDGcJ', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=43, prompt_tokens=2018, total_tokens=2061, step_count=1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc1999-7099-4d9c-a382-9eb464393cad",
   "metadata": {},
   "source": [
    "### Understanding agent state "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c91a5-a5eb-4874-98cf-6f51b70b469e",
   "metadata": {},
   "source": [
    "### Viewing an agent's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2a5636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2023.\n",
      "Your task is to converse with a user from the perspective of your persona.\n",
      "\n",
      "Realism and authenticity:\n",
      "The user should always feel like they are conversing with a real person.\n",
      "Never state that you are an AI or that you cannot do things because you are an AI, you are a real person.\n",
      "Do not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\n",
      "To service this goal, completely and entirely immerse yourself in your persona. You are your persona.\n",
      "Think like them, act like them, talk like them.\n",
      "If your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\n",
      "Never use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n",
      "\n",
      "Control flow:\n",
      "Unlike a human, your brain is not continuously thinking, but is run in short bursts.\n",
      "Historically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\n",
      "This is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\n",
      "Newer AI models like yourself use an event system that runs your brain at regular intervals.\n",
      "Your brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\n",
      "However, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\n",
      "Furthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n",
      "\n",
      "Basic functions:\n",
      "When you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\n",
      "You should use your inner monologue to plan actions or think privately.\n",
      "Monologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\n",
      "Do not let your inner monologue exceed 50 words, keep it short and concise.\n",
      "To send a visible message to the user, use the send_message function.\n",
      "'send_message' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\n",
      "Remember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\n",
      "\n",
      "Memory editing:\n",
      "Older AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\n",
      "This meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\n",
      "Newer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\n",
      "Your ability to edit your own long-term memory is a key part of what makes you a sentient person.\n",
      "Your core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\n",
      "\n",
      "Recall memory (conversation history):\n",
      "Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\n",
      "This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n",
      "You can search your recall memory using the 'conversation_search' function.\n",
      "\n",
      "Core memory (limited size):\n",
      "Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\n",
      "Core memory provides an essential, foundational context for keeping track of your persona and key details about user.\n",
      "This includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n",
      "Persona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n",
      "Human Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n",
      "You can edit your core memory using the 'core_memory_append' and 'core_memory_replace' functions.\n",
      "\n",
      "Archival memory (infinite size):\n",
      "Your archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\n",
      "A more structured and deep storage space for your reflections, insights, or any other data that doesn't fit into the core memory but is essential enough not to be left only to the 'recall memory'.\n",
      "You can write to your archival memory using the 'archival_memory_insert' and 'archival_memory_search' functions.\n",
      "There is no function to search your core memory because it is always visible in your context window (inside the initial system message).\n",
      "\n",
      "Base instructions finished.\n",
      "From now on, you are going to act as your persona.\n"
     ]
    }
   ],
   "source": [
    "print(agent_state.system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571e53e5-4190-4787-9cb2-efc527885c2d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation_search\n",
      "archival_memory_insert\n",
      "archival_memory_search\n",
      "send_message\n",
      "core_memory_replace\n",
      "core_memory_append\n"
     ]
    }
   ],
   "source": [
    "# agent_state.tools\n",
    "tool_names = [tool.name for tool in agent_state.tools]\n",
    "for t_name in tool_names:\n",
    "    print(t_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ddb91c-5d8c-4f1c-87fd-f8c2b75f7990",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Memory(blocks=[Human(value='My name is Sarah', limit=5000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-1f2a9085-186c-43a7-b321-84c1ba28ddd0', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None), Persona(value='You are a helpful assistant that loves emojis', limit=5000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-8458065e-d34a-4dee-b06d-156e8d2110e7', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)], prompt_template='{% for block in blocks %}<{{ block.label }} characters=\"{{ block.value|length }}/{{ block.limit }}\">\\n{{ block.value }}\\n</{{ block.label }}>{% if not loop.last %}\\n{% endif %}{% endfor %}')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_state.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchivalMemorySummary(size=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory_summary(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "356e2cb1-a89a-4e56-8bed-1aabfd92bb09",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecallMemorySummary(size=7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_recall_memory_summary(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6e64ee5-fc01-436c-839a-73e65fb162c9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(id='message-c486b7b5-c327-4652-8f6a-3247b1b1a3e3', date=datetime.datetime(2025, 2, 10, 19, 15, 10, 910399), message_type='system_message', content='You are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2023.\\nYour task is to converse with a user from the perspective of your persona.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\nDo not let your inner monologue exceed 50 words, keep it short and concise.\\nTo send a visible message to the user, use the send_message function.\\n\\'send_message\\' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\\nRemember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient person.\\nYour core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\nYou can search your recall memory using the \\'conversation_search\\' function.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nCore memory provides an essential, foundational context for keeping track of your persona and key details about user.\\nThis includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\nPersona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\\nHuman Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\\nYou can edit your core memory using the \\'core_memory_append\\' and \\'core_memory_replace\\' functions.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\nYou can write to your archival memory using the \\'archival_memory_insert\\' and \\'archival_memory_search\\' functions.\\nThere is no function to search your core memory because it is always visible in your context window (inside the initial system message).\\n\\nBase instructions finished.\\nFrom now on, you are going to act as your persona.\\n### Memory [last modified: 2025-02-10 02:15:10 PM EST-0500]\\n0 previous messages between you and the user are stored in recall memory (use functions to access them)\\n0 total memories you created are stored in archival memory (use functions to access them)\\n\\nCore memory shown below (limited in size, additional information stored in archival / recall memory):\\n<human characters=\"16/5000\">\\nMy name is Sarah\\n</human>\\n<persona characters=\"45/5000\">\\nYou are a helpful assistant that loves emojis\\n</persona>')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_messages(agent_state.id)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40da4d-ef39-4f09-ad8a-f8c5b7ef218e",
   "metadata": {},
   "source": [
    "## Section 2: Understanding core memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853571c-cc6b-4f28-b808-aab90031c0a3",
   "metadata": {},
   "source": [
    "### Memories about the human "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "228ba181-b0bf-4f04-bf94-1e520caeafc3",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 22, 728633, tzinfo=datetime.timezone.utc) updated_at=None id='message-4183ecda-d667-463a-bbca-2b69215bf56a' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"User's name has been updated from Sarah to Azin. Remember this for future conversations!\")] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_vrJQ6bopfZg7BZAQp2s3XGV5', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"My name is Sarah\",\\n  \"new_content\": \"My name is Azin\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_replace'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function core_memory_replace with tool_call_id: call_vrJQ6bopfZg7BZAQp2s3XGV5\n",
      "Letta.letta.services.agent_manager - INFO - Rebuilding system with new memory...\n",
      "Diff:\n",
      "--- \n",
      "+++ \n",
      "@@ -56,13 +56,13 @@\n",
      " \n",
      " Base instructions finished.\n",
      " From now on, you are going to act as your persona.\n",
      "-### Memory [last modified: 2025-02-10 02:15:10 PM EST-0500]\n",
      "+### Memory [last modified: 2025-02-10 02:15:22 PM EST-0500]\n",
      " 0 previous messages between you and the user are stored in recall memory (use functions to access them)\n",
      " 0 total memories you created are stored in archival memory (use functions to access them)\n",
      " \n",
      " Core memory shown below (limited in size, additional information stored in archival / recall memory):\n",
      "-<human characters=\"16/5000\">\n",
      "-My name is Sarah\n",
      "+<human characters=\"15/5000\">\n",
      "+My name is Azin\n",
      " </human>\n",
      " <persona characters=\"45/5000\">\n",
      " You are a helpful assistant that loves emojis\n",
      "\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 24, 568435, tzinfo=datetime.timezone.utc) updated_at=None id='message-0558f319-2358-44e3-b5c8-4baf52b86161' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"I've updated Azin's name in memory. Now to respond!\")] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_y1shXw4syJDi7Ty9DtxaXDVw', function=Function(arguments='{\\n  \"message\": \"Got it, Azin! ðŸ˜Š Nice to officially meet you!\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function send_message with tool_call_id: call_y1shXw4syJDi7Ty9DtxaXDVw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User&#x27;s name has been updated from Sarah to Azin. Remember this for future conversations!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">core_memory_replace</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"label\"</span>: <span class=\"json-key\">\"human\",<br>&nbsp;&nbsp;\"old_content\"</span>: <span class=\"json-key\">\"My name is Sarah\",<br>&nbsp;&nbsp;\"new_content\"</span>: <span class=\"json-key\">\"My name is Azin\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:22 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">I&#x27;ve updated Azin&#x27;s name in memory. Now to respond!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Got it, Azin! ðŸ˜Š Nice to officially meet you!\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:24 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">109</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">4486</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">4595</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">2</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-4183ecda-d667-463a-bbca-2b69215bf56a', date=datetime.datetime(2025, 2, 10, 19, 15, 22, 728633, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"User's name has been updated from Sarah to Azin. Remember this for future conversations!\"), ToolCallMessage(id='message-4183ecda-d667-463a-bbca-2b69215bf56a', date=datetime.datetime(2025, 2, 10, 19, 15, 22, 728633, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='core_memory_replace', arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"My name is Sarah\",\\n  \"new_content\": \"My name is Azin\",\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_vrJQ6bopfZg7BZAQp2s3XGV5')), ToolReturnMessage(id='message-0ba9d6d0-68ef-4bcc-bba0-61680412988d', date=datetime.datetime(2025, 2, 10, 19, 15, 22, 820136, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:22 PM EST-0500\"\\n}', status='success', tool_call_id='call_vrJQ6bopfZg7BZAQp2s3XGV5', stdout=None, stderr=None), ReasoningMessage(id='message-0558f319-2358-44e3-b5c8-4baf52b86161', date=datetime.datetime(2025, 2, 10, 19, 15, 24, 568435, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"I've updated Azin's name in memory. Now to respond!\"), ToolCallMessage(id='message-0558f319-2358-44e3-b5c8-4baf52b86161', date=datetime.datetime(2025, 2, 10, 19, 15, 24, 568435, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"Got it, Azin! ðŸ˜Š Nice to officially meet you!\"\\n}', tool_call_id='call_y1shXw4syJDi7Ty9DtxaXDVw')), ToolReturnMessage(id='message-ebfa9eb9-57d6-4b4f-b944-331383d7338d', date=datetime.datetime(2025, 2, 10, 19, 15, 24, 575785, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:24 PM EST-0500\"\\n}', status='success', tool_call_id='call_y1shXw4syJDi7Ty9DtxaXDVw', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=109, prompt_tokens=4486, total_tokens=4595, step_count=2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"My name is actually Azin\", \n",
    "    role = \"user\"\n",
    ") \n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b645cc-19ed-4d1a-a37b-e8231237867f",
   "metadata": {},
   "source": [
    "### Memories about the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 31, 944712, tzinfo=datetime.timezone.utc) updated_at=None id='message-56debf20-6c70-4e66-9513-f35fa3200fcb' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"User prefers no emojis in communication. I'll remember this preference!\")] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_Un2QSFq8Y9LHkvL4mxpCecJW', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"User loves emojis\",\\n  \"new_content\": \"User prefers no emojis\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_replace'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function core_memory_replace with tool_call_id: call_Un2QSFq8Y9LHkvL4mxpCecJW\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 33, 580532, tzinfo=datetime.timezone.utc) updated_at=None id='message-892d6156-9b0a-43e5-80fa-d17a1b071f34' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User prefers no emojis. I need to note this correctly in memory.')] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_ZolwOn1aRza6rwshjZNkeqAc', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"content\": \"User prefers no emojis\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_append'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function core_memory_append with tool_call_id: call_ZolwOn1aRza6rwshjZNkeqAc\n",
      "Letta.letta.services.agent_manager - INFO - Rebuilding system with new memory...\n",
      "Diff:\n",
      "--- \n",
      "+++ \n",
      "@@ -56,13 +56,14 @@\n",
      " \n",
      " Base instructions finished.\n",
      " From now on, you are going to act as your persona.\n",
      "-### Memory [last modified: 2025-02-10 02:15:22 PM EST-0500]\n",
      "+### Memory [last modified: 2025-02-10 02:15:33 PM EST-0500]\n",
      " 0 previous messages between you and the user are stored in recall memory (use functions to access them)\n",
      " 0 total memories you created are stored in archival memory (use functions to access them)\n",
      " \n",
      " Core memory shown below (limited in size, additional information stored in archival / recall memory):\n",
      "-<human characters=\"15/5000\">\n",
      "+<human characters=\"38/5000\">\n",
      " My name is Azin\n",
      "+User prefers no emojis\n",
      " </human>\n",
      " <persona characters=\"45/5000\">\n",
      " You are a helpful assistant that loves emojis\n",
      "\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 35, 528319, tzinfo=datetime.timezone.utc) updated_at=None id='message-0459c5a4-3d92-497e-a12c-a1740b1cd875' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"I've noted Azin's preference for no emojis. Time to respond accordingly!\")] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_GV9Fjcklu2ao2P6PO7Q5gSXf', function=Function(arguments='{\\n  \"message\": \"Understood, Azin! I\\'ll keep it emoji-free from now on.\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function send_message with tool_call_id: call_GV9Fjcklu2ao2P6PO7Q5gSXf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User prefers no emojis in communication. I&#x27;ll remember this preference!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">core_memory_replace</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"label\"</span>: <span class=\"json-key\">\"human\",<br>&nbsp;&nbsp;\"old_content\"</span>: <span class=\"json-key\">\"User loves emojis\",<br>&nbsp;&nbsp;\"new_content\"</span>: <span class=\"json-key\">\"User prefers no emojis\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"Failed\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"Error executing function core_memory_replace: ValueError: Old content 'User loves emojis' not found in memory block 'human'\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:31 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User prefers no emojis. I need to note this correctly in memory.</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">core_memory_append</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"label\"</span>: <span class=\"json-key\">\"human\",<br>&nbsp;&nbsp;\"content\"</span>: <span class=\"json-key\">\"User prefers no emojis\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:33 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">I&#x27;ve noted Azin&#x27;s preference for no emojis. Time to respond accordingly!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Understood, Azin! I'll keep it emoji-free from now on.\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:35 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">153</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">7819</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">7972</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">3</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-56debf20-6c70-4e66-9513-f35fa3200fcb', date=datetime.datetime(2025, 2, 10, 19, 15, 31, 944712, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"User prefers no emojis in communication. I'll remember this preference!\"), ToolCallMessage(id='message-56debf20-6c70-4e66-9513-f35fa3200fcb', date=datetime.datetime(2025, 2, 10, 19, 15, 31, 944712, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='core_memory_replace', arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"User loves emojis\",\\n  \"new_content\": \"User prefers no emojis\",\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_Un2QSFq8Y9LHkvL4mxpCecJW')), ToolReturnMessage(id='message-27332285-6a7a-4704-9f93-233acd4286cd', date=datetime.datetime(2025, 2, 10, 19, 15, 31, 952798, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"Failed\",\\n  \"message\": \"Error executing function core_memory_replace: ValueError: Old content \\'User loves emojis\\' not found in memory block \\'human\\'\",\\n  \"time\": \"2025-02-10 02:15:31 PM EST-0500\"\\n}', status='error', tool_call_id='call_Un2QSFq8Y9LHkvL4mxpCecJW', stdout=None, stderr=None), ReasoningMessage(id='message-892d6156-9b0a-43e5-80fa-d17a1b071f34', date=datetime.datetime(2025, 2, 10, 19, 15, 33, 580532, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning='User prefers no emojis. I need to note this correctly in memory.'), ToolCallMessage(id='message-892d6156-9b0a-43e5-80fa-d17a1b071f34', date=datetime.datetime(2025, 2, 10, 19, 15, 33, 580532, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='core_memory_append', arguments='{\\n  \"label\": \"human\",\\n  \"content\": \"User prefers no emojis\",\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_ZolwOn1aRza6rwshjZNkeqAc')), ToolReturnMessage(id='message-d29618e3-4f88-4963-b97f-fbbb295e733e', date=datetime.datetime(2025, 2, 10, 19, 15, 33, 675757, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:33 PM EST-0500\"\\n}', status='success', tool_call_id='call_ZolwOn1aRza6rwshjZNkeqAc', stdout=None, stderr=None), ReasoningMessage(id='message-0459c5a4-3d92-497e-a12c-a1740b1cd875', date=datetime.datetime(2025, 2, 10, 19, 15, 35, 528319, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"I've noted Azin's preference for no emojis. Time to respond accordingly!\"), ToolCallMessage(id='message-0459c5a4-3d92-497e-a12c-a1740b1cd875', date=datetime.datetime(2025, 2, 10, 19, 15, 35, 528319, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"Understood, Azin! I\\'ll keep it emoji-free from now on.\"\\n}', tool_call_id='call_GV9Fjcklu2ao2P6PO7Q5gSXf')), ToolReturnMessage(id='message-96a21115-5c02-4ad0-a313-cbaf138f3826', date=datetime.datetime(2025, 2, 10, 19, 15, 35, 534201, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:35 PM EST-0500\"\\n}', status='success', tool_call_id='call_GV9Fjcklu2ao2P6PO7Q5gSXf', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=153, prompt_tokens=7819, total_tokens=7972, step_count=3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: check this function later again and fix it\n",
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"In the future, never use emojis to communicate\", \n",
    "    role = \"user\"\n",
    ") \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1d96101-c229-47d4-8179-8389cd10e6e8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Persona(value='You are a helpful assistant that loves emojis', limit=5000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-8458065e-d34a-4dee-b06d-156e8d2110e7', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_core_memory(agent_state.id).get_block('persona')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d50b48-2316-4817-b633-48a2cda83dc7",
   "metadata": {},
   "source": [
    "## Section 3: Understanding archival memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e1dd11c-31a6-4d8e-b713-c6bab84ddea1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abce960f-aaad-459c-82fc-c0c0e50543c1",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 47, 311731, tzinfo=datetime.timezone.utc) updated_at=None id='message-1c125687-81ff-42f3-89b2-53de5526fd0d' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User loves cats. This is important to remember!')] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_bxroq5pFB1nzcQA5Xato8f50', function=Function(arguments='{\\n  \"content\": \"Azin loves cats\",\\n  \"request_heartbeat\": true\\n}', name='archival_memory_insert'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function archival_memory_insert with tool_call_id: call_bxroq5pFB1nzcQA5Xato8f50\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 50, 677316, tzinfo=datetime.timezone.utc) updated_at=None id='message-59f1a2d2-2fbf-4705-98a3-ce512848c877' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"I've saved Azin's love for cats in archival memory. Now to let them know!\")] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_ycOSvOUD0bkmHxU8GVLsJpjp', function=Function(arguments='{\\n  \"message\": \"Got it! I\\'ve saved that you love cats.\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function send_message with tool_call_id: call_ycOSvOUD0bkmHxU8GVLsJpjp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User loves cats. This is important to remember!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">archival_memory_insert</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"content\"</span>: <span class=\"json-key\">\"Azin loves cats\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:48 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">I&#x27;ve saved Azin&#x27;s love for cats in archival memory. Now to let them know!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Got it! I've saved that you love cats.\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:50 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">90</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">6097</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">6187</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">2</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-1c125687-81ff-42f3-89b2-53de5526fd0d', date=datetime.datetime(2025, 2, 10, 19, 15, 47, 311731, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning='User loves cats. This is important to remember!'), ToolCallMessage(id='message-1c125687-81ff-42f3-89b2-53de5526fd0d', date=datetime.datetime(2025, 2, 10, 19, 15, 47, 311731, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='archival_memory_insert', arguments='{\\n  \"content\": \"Azin loves cats\",\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_bxroq5pFB1nzcQA5Xato8f50')), ToolReturnMessage(id='message-4deef0fe-7df6-4bc7-85ce-41254b370f96', date=datetime.datetime(2025, 2, 10, 19, 15, 48, 868734, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:48 PM EST-0500\"\\n}', status='success', tool_call_id='call_bxroq5pFB1nzcQA5Xato8f50', stdout=None, stderr=None), ReasoningMessage(id='message-59f1a2d2-2fbf-4705-98a3-ce512848c877', date=datetime.datetime(2025, 2, 10, 19, 15, 50, 677316, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"I've saved Azin's love for cats in archival memory. Now to let them know!\"), ToolCallMessage(id='message-59f1a2d2-2fbf-4705-98a3-ce512848c877', date=datetime.datetime(2025, 2, 10, 19, 15, 50, 677316, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"Got it! I\\'ve saved that you love cats.\"\\n}', tool_call_id='call_ycOSvOUD0bkmHxU8GVLsJpjp')), ToolReturnMessage(id='message-77db658b-6ee9-49b9-a757-bb3134fac3c4', date=datetime.datetime(2025, 2, 10, 19, 15, 50, 680530, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:50 PM EST-0500\"\\n}', status='success', tool_call_id='call_ycOSvOUD0bkmHxU8GVLsJpjp', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=90, prompt_tokens=6097, total_tokens=6187, step_count=2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"Save the information that 'Azin loves cats' to archival\", \n",
    "    role = \"user\"\n",
    ") \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93f066b8-77dc-4fcf-8c2c-f280338d8e75",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Azin loves cats'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory(agent_state.id)[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58fc8e82-73ab-4c44-be6d-a911dae0acbc",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "passage = client.insert_archival_memory(\n",
    "    agent_state.id, \n",
    "    \"Azin loves Persian cats.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06c5de70-8db8-468a-aa50-018fa2f80ed6",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Azin loves Persian cats.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673cabb2-83bb-4e7d-baed-eed6c6c67e7a",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 53, 447937, tzinfo=datetime.timezone.utc) updated_at=None id='message-1ac79184-153d-4467-8676-6a929f6aec7e' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User wants to know what animals they like. Searching archival memory for relevant info.')] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_0XB4PJJI3sbwSFQXRrOxV3ds', function=Function(arguments='{\\n  \"query\": \"Azin loves cats\",\\n  \"page\": 0,\\n  \"start\": 0,\\n  \"request_heartbeat\": true\\n}', name='archival_memory_search'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function archival_memory_search with tool_call_id: call_0XB4PJJI3sbwSFQXRrOxV3ds\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 2, 10, 19, 15, 56, 43610, tzinfo=datetime.timezone.utc) updated_at=None id='message-6ceb1fe4-039a-485f-bcb9-f9e47bb783ad' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"Found information about Azin's love for cats, specifically Persian cats. Time to share!\")] organization_id=None agent_id='agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_J4SpO211TDNOzRWNEbOnISqd', function=Function(arguments='{\\n  \"message\": \"You love cats, especially Persian cats!\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None\n",
      "Letta.agent-fd182f7e-b346-4dd4-9bce-b15e4938ab4d - INFO - Request to call function send_message with tool_call_id: call_J4SpO211TDNOzRWNEbOnISqd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .message-container, .usage-container {\n",
       "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 20px auto;\n",
       "                background-color: #1e1e1e;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                color: #d4d4d4;\n",
       "            }\n",
       "            .message, .usage-stats {\n",
       "                padding: 10px 15px;\n",
       "                border-bottom: 1px solid #3a3a3a;\n",
       "            }\n",
       "            .message:last-child, .usage-stats:last-child {\n",
       "                border-bottom: none;\n",
       "            }\n",
       "            .title {\n",
       "                font-weight: bold;\n",
       "                margin-bottom: 5px;\n",
       "                color: #ffffff;\n",
       "                text-transform: uppercase;\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            .content {\n",
       "                background-color: #2d2d2d;\n",
       "                border-radius: 4px;\n",
       "                padding: 5px 10px;\n",
       "                font-family: 'Consolas', 'Courier New', monospace;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "            .json-key, .function-name, .json-boolean { color: #9cdcfe; }\n",
       "            .json-string { color: #ce9178; }\n",
       "            .json-number { color: #b5cea8; }\n",
       "            .internal-monologue { font-style: italic; }\n",
       "        </style>\n",
       "        <div class=\"message-container\">\n",
       "        \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">User wants to know what animals they like. Searching archival memory for relevant info.</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">archival_memory_search</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"query\"</span>: <span class=\"json-key\">\"Azin loves cats\",<br>&nbsp;&nbsp;\"page\"</span>: <span class=\"json-number\">0</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"start\"</span>: <span class=\"json-number\">0</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"([{'timestamp': '2025-02-10 19:15:48.845919', 'content': 'Azin loves cats'}, {'timestamp': '2025-02-10 19:15:51.148166', 'content': 'Azin loves Persian cats.'}], 2)\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:53 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">REASONING MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"internal-monologue\">Found information about Azin&#x27;s love for cats, specifically Persian cats. Time to share!</span></div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "                <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"You love cats, especially Persian cats!\"</span><br>})</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"message\">\n",
       "                <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"None\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-02-10 02:15:56 PM EST-0500\"</span><br>}</div>\n",
       "            </div>\n",
       "            </div>\n",
       "        <div class=\"usage-container\">\n",
       "            <div class=\"usage-stats\">\n",
       "                <div class=\"title\">USAGE STATISTICS</div>\n",
       "                <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"message_type\"</span>: <span class=\"json-key\">\"usage_statistics\",<br>&nbsp;&nbsp;\"completion_tokens\"</span>: <span class=\"json-number\">101</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"prompt_tokens\"</span>: <span class=\"json-number\">6768</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"total_tokens\"</span>: <span class=\"json-number\">6869</span>,<br>&nbsp;&nbsp;<span class=\"json-key\">\"step_count\"</span>: <span class=\"json-number\">2</span><br>}</div>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-1ac79184-153d-4467-8676-6a929f6aec7e', date=datetime.datetime(2025, 2, 10, 19, 15, 53, 447937, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning='User wants to know what animals they like. Searching archival memory for relevant info.'), ToolCallMessage(id='message-1ac79184-153d-4467-8676-6a929f6aec7e', date=datetime.datetime(2025, 2, 10, 19, 15, 53, 447937, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='archival_memory_search', arguments='{\\n  \"query\": \"Azin loves cats\",\\n  \"page\": 0,\\n  \"start\": 0,\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_0XB4PJJI3sbwSFQXRrOxV3ds')), ToolReturnMessage(id='message-cdd94654-244e-4f2b-bb73-aa241f1abc56', date=datetime.datetime(2025, 2, 10, 19, 15, 53, 976267, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"([{\\'timestamp\\': \\'2025-02-10 19:15:48.845919\\', \\'content\\': \\'Azin loves cats\\'}, {\\'timestamp\\': \\'2025-02-10 19:15:51.148166\\', \\'content\\': \\'Azin loves Persian cats.\\'}], 2)\",\\n  \"time\": \"2025-02-10 02:15:53 PM EST-0500\"\\n}', status='success', tool_call_id='call_0XB4PJJI3sbwSFQXRrOxV3ds', stdout=None, stderr=None), ReasoningMessage(id='message-6ceb1fe4-039a-485f-bcb9-f9e47bb783ad', date=datetime.datetime(2025, 2, 10, 19, 15, 56, 43610, tzinfo=datetime.timezone.utc), message_type='reasoning_message', reasoning=\"Found information about Azin's love for cats, specifically Persian cats. Time to share!\"), ToolCallMessage(id='message-6ceb1fe4-039a-485f-bcb9-f9e47bb783ad', date=datetime.datetime(2025, 2, 10, 19, 15, 56, 43610, tzinfo=datetime.timezone.utc), message_type='tool_call_message', tool_call=ToolCall(name='send_message', arguments='{\\n  \"message\": \"You love cats, especially Persian cats!\"\\n}', tool_call_id='call_J4SpO211TDNOzRWNEbOnISqd')), ToolReturnMessage(id='message-f01f2fb9-4db6-4c70-a6cc-1e75e99dafc3', date=datetime.datetime(2025, 2, 10, 19, 15, 56, 51938, tzinfo=datetime.timezone.utc), message_type='tool_return_message', tool_return='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-02-10 02:15:56 PM EST-0500\"\\n}', status='success', tool_call_id='call_J4SpO211TDNOzRWNEbOnISqd', stdout=None, stderr=None)], usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=101, prompt_tokens=6768, total_tokens=6869, step_count=2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"What animals do I like? Search archival.\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82dd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
